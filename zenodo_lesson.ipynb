{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37ae2c02",
   "metadata": {},
   "source": [
    "# Introduction + Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecd2ac8",
   "metadata": {},
   "source": [
    "Hi everyone. My name is Michael, and I'm a master's student at UCSD studying machine learning and data science. I've been working with the UCSD Library's Data Curation team for the last 8 months to build a data collection tool that scrapes APIs and websites. This workshop is going to take you all through the first steps that I went through in order to collect API data in a robust and reproducible way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda49477",
   "metadata": {},
   "source": [
    "To start off, we're assuming that everyone here has at least a basic understanding of what an API is, and is comfortable programming in Python. Since this is a workshop, we encourage you all to follow along on your own computer. If you don't have jupyter or another Python environment set up, you can use [Google Colab](https://colab.research.google.com) to write your code. I'll paste a link to that in the chat, and we can wait a minute or so in case anyone wants to get that loaded before we get started. Once you're ready to go, or if you're not planning on coding with us, go ahead and click on the green checkmark in the reactions tab so we know when everyone is ready. If anyone has any questions, you can ask in the chat. If you're more comfortable sending it privately, you can send it to Dennis, Kat, or Jamie, and they'll make sure that I get it answered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e3d48e",
   "metadata": {},
   "source": [
    "While everyone is getting their environments ready, there is an optional package I'll be using to better understand the structure of our query results, which is the ```flatten_json``` package. This can be installed by \n",
    "\n",
    "```bash\n",
    "pip install flatten_json\n",
    "```\n",
    "\n",
    "We'll also be making use of ```pandas```. If you're working with Python through Google Colab or an Anaconda installation, it should already be installed, but if you need to download it,\n",
    "\n",
    "```bash\n",
    "pip install pandas\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ab4903",
   "metadata": {},
   "source": [
    "# Background Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923ffa3f",
   "metadata": {},
   "source": [
    "Today we'll be going through the full process of requesting the data we want from a REST API. For this workshop, we're focusing on Zenodo. Zenodo is an online Open Science research repository, which houses close to two and a half million publications, datasets, codebases, and other research related items. This makes it a great API to explore because there is a ton of data that we can collect. \n",
    "\n",
    "[Zenodo](https://zenodo.org)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c723860c",
   "metadata": {},
   "source": [
    "Before we get started with any API, we need to check out the documentation to get familiar with the querying process. A lot of API's that you run into will work pretty similarly, but we still need to get the specifics.\n",
    "\n",
    "[Zenodo API](https://developers.zenodo.org)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110bd9ec",
   "metadata": {},
   "source": [
    "Taking a look at the documentation, there are a few key points to take note of.\n",
    "First, we see that Zenodo uses a REST API, which means that we're going to be wanting to use the ```requests``` library in python to make our queries.\n",
    "\n",
    "Second, we see that there's a section on authenticating our requests over HTTPS. Although the section outlines that the requests will fail if they're not authenticated, we don't actually need to go through the process of creating a personal token and authenticating for simple data queries to Zenodo. I'm not sure why, but it makes this demo a bit less cumbersome.\n",
    "\n",
    "Third, we see that the base url for our requests is given (```https://zenodo.org/api/```), so we need to take note of that for later.\n",
    "\n",
    "Continuing through, we see the standards that our responses will be JSON objects and successful responses will have a status_code of 200.\n",
    "\n",
    "Now for the actual queries, we want to be searching over the records. This section tells us that the query url is going to be ```'https://zenodo.org/api/records'```, and it gives us some insight on the different parameters that we can use to perform a search. Now for this application, let's say that we're interested in collecting all of the records that Zenodo has on basketball. Since we want to collect all of the records, we won't need to worry about a lot of the parameters that restrict the search. Instead, we'll mainly be focusing on \n",
    "\n",
    "- q: The Elasticsearch query string search query\n",
    "- page: Page number of results\n",
    "- size: The number of result per page.\n",
    "\n",
    "This means that the results are paginated, which is common for APIs that could potentially return a lot of data. If our query had a few hundred thousands results, returning all of them in one set wouldn't be feasible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c2682a",
   "metadata": {},
   "source": [
    "Now that we've got a rough idea of how we can work with the API, let's dive into it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7be957c",
   "metadata": {},
   "source": [
    "# Importing the necessary librarys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3178ffc",
   "metadata": {},
   "source": [
    "There are a couple of different librarys that we're going to be using, so let's start out importing them all at the top in order to keep the full code a bit cleaner.\n",
    "\n",
    "1. ```requests``` \n",
    "    Since we're working with a REST API, we're going to want to use the requests library in order to send our requests to the API.\n",
    "    \n",
    "2. ```pandas```\n",
    "    Since we're making a handful of requests and need to store them, we're going to use Pandas DataFrames to keep all of our responses in one place.\n",
    "    \n",
    "3. ```flatten_json```\n",
    "    We saw that the data is returned in a JSON format. It'll be helpful to be able to view the \"nested\" JSON data in a flatter form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db9f520",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from flatten_json import flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51f18a7",
   "metadata": {},
   "source": [
    "# Making Requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae09b89",
   "metadata": {},
   "source": [
    "As a refresher, let's take a look at how we make a request in general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1863db18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = requests.get(url, params, headers)\n",
    "r = requests.get(\"http://www.example.com/\")\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63f1bc4",
   "metadata": {},
   "source": [
    "When we call the request.get module, it returns the response object, which is represented by the reponse code. In this case we have a 200 response, which means the request was successful. \n",
    "\n",
    "Next, let's break down what the full result contains. Python has a neat function called ```vars()``` which lets us see all the dictionary representation of an object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccaac7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef52be6",
   "metadata": {},
   "source": [
    "Now that we've got an idea about how these requests are formatted and how to make a request to Zenodo, let's try it out. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207d144e",
   "metadata": {},
   "source": [
    "## General Zenodo Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4207de",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(\"https://zenodo.org/api/records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d45533",
   "metadata": {},
   "source": [
    "So recall that the documentation mentioned that the response is given in JSON format, so let's take a look at what it gives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a283d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = r.json()\n",
    "output.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1054de18",
   "metadata": {},
   "source": [
    "We can see that the output is structured into \"aggregations\", \"hits\", and \"links\", so let's take a look at what each of those are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f900d89c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output['aggregations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4649ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "output['hits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b1cf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output['links']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27684a83",
   "metadata": {},
   "source": [
    "At first glance, it seems like aggregations is giving us some high level statistics about the breakdown of our query. Since we didn't make any specifications for search terms or time periods, it's reporting on all 2.3 million Zenodo records. The links data is giving some information on the current query and the next potential query page. And lastly, there's the hits data, which seems like what we really want. Although it looks like this is nested, so let's take a look at the breakdown of that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f03b44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output['hits'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c853e98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output['hits']['total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578b9844",
   "metadata": {},
   "outputs": [],
   "source": [
    "output['hits']['hits']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302a3c3e",
   "metadata": {},
   "source": [
    "So it looks like the total attribute of the hits is more high level information about the query, and the hits attribute contains the information that we're after. This looks pretty messy though, so we'll clean it up a bit by putting it into a DataFrame, which is easy to do since the JSON representations are stored as dictionarys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043d07cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(output['hits']['hits'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2432c245",
   "metadata": {},
   "source": [
    "Looking at the DataFrame, there's even more JSON nested in the hits data. This is getting kind of twisted, so let's just flatten the data and take a look at that to see what we're really getting back. First, let's take a look at the ```flatten_json``` functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07249101",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_json.flatten?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0b10f9",
   "metadata": {},
   "source": [
    "So the ```flatten``` function takes a dictionary, but we're dealing with a list of dictionarys, and we need to flatten all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f43e360",
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_hits = [flatten(json_dict) for json_dict in output['hits']['hits']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e333344",
   "metadata": {},
   "source": [
    "That's actually going to come in handy a bunch, so we'll functionize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0239979b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list(dicts):\n",
    "    \"\"\"Flatten iterable of nested dictionaries.\"\"\"\n",
    "    # Need to make sure we don't accidentally pass in the wrong data\n",
    "    assert all([isinstance(d, dict) for d in dicts])\n",
    "    \n",
    "    return [flatten(d) for d in dicts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97811f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(flattened_hits)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68dd1a1",
   "metadata": {},
   "source": [
    "That's much more manageable to read, but now our DataFrame has 153 columns instead of just 12. This can be handy if we need all of the data in a flat format, but definitely be careful when you're unnesting content that can balloon up like that. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97996afa",
   "metadata": {},
   "source": [
    "## Specific Zenodo Requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc1872d",
   "metadata": {},
   "source": [
    "Now that we've seen how the general format of Zenodo requests are, we can finally move forward with getting all of the specific basketball data that we want."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc47a7c",
   "metadata": {},
   "source": [
    "In order to make the request, we have to pass those parameters to the ```params``` argument in the ```requests.get()``` function, which takes a dictionary. Let's set it up now so that we can continue to reference it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39a54ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_records_url = 'https://zenodo.org/api/records'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f555ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params = {'q': 'basketball'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d04eee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(url = zenodo_records_url, params=search_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc1e9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = r.json()\n",
    "hits = output['hits']['hits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4bc3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(hits)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709258c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6937725",
   "metadata": {},
   "source": [
    "And now we can see that we're getting out basketball results back. Although we're only getting 10 results, so we need to use the pagination parameters that we read about earlier. To make this easier, let's put this into a function too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a3d0b7",
   "metadata": {},
   "source": [
    "First, let's quickly check the assumptions that we're making so that our function doesn't crash. We're assuming that we're going to search for a string, since that's what Zenodo requires. We're assuming that we get a proper 200 status code. We're also assuming that the results are given in the ```r.json()``` nested hits hits item. Is this always going to happen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcd35d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(zenodo_records_url, params={'q': 'fjkdajfeiowajtio'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f529e4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ca9371",
   "metadata": {},
   "source": [
    "Now we see that ```output['hits']['hits']``` doesn't exist. so we need to be careful about just indexing the output dictionary when it might be empty. If we aren't sure that a dictionary has a key or not, we can use the ```dict.get()``` function to be safe. By default, an improper key will return None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c638c262",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zenodo_search_output(search_term, page, size):\n",
    "    \"\"\"Return the output for a Zenodo record query.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    search_term : str\n",
    "    page : int\n",
    "    size : int\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    output_df : pandas.DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    assert isinstance(search_term, str)\n",
    "    assert isinstance(page, int)\n",
    "    assert isinstance(size, int)\n",
    "    \n",
    "    search_url = 'https://zenodo.org/api/records'\n",
    "    search_params = {'q': search_term, 'page': page, 'size': size}\n",
    "    \n",
    "    r = requests.get(search_url, params=search_params)\n",
    "    output = r.json()\n",
    "    \n",
    "    if r.status_code == 200 and output.get('hits').get('hits'):\n",
    "        output_df = pd.DataFrame(output['hits']['hits'])\n",
    "    else:\n",
    "        return r\n",
    "    \n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c98c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_zenodo_search_output('basketball', 1, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5caf3f",
   "metadata": {},
   "source": [
    "Awesome, now we're able to get more results and only call one line of code to do it. Let's test it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d9a9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = get_zenodo_search_output('basketball', 100, 1000)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f48ec03",
   "metadata": {},
   "source": [
    "Now we see that we're getting a 400 response, so let's check it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8ff37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fe64c1",
   "metadata": {},
   "source": [
    "So we can't search for more than 10,000 results at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab384b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "requests.get(zenodo_records_url, params={'q': 'basketball'}).json()['hits']['total']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eee63ae",
   "metadata": {},
   "source": [
    "Luckily we won't run into any 10,000 limit issues, but if we have time, let's try to figure out how we could get around this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03e4128",
   "metadata": {},
   "source": [
    "## Getting More Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e032ea",
   "metadata": {},
   "source": [
    "In order to get all of the records, we need to search over every page. Since we saw that there's a ```link``` attribute returned, let's continue to search that next link as long as it exists. In order to see what behavior to expect when we run out of pages, let's search the end results (which we can do since we know how many total records there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c968423",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(zenodo_records_url, params={'q': 'basketball', 'page': 4, 'size': 100})\n",
    "output = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c844058",
   "metadata": {},
   "outputs": [],
   "source": [
    "output['links']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093b8467",
   "metadata": {},
   "source": [
    "When there's no more pages, they just don't return a ```next``` link. So a potential loop for this could be something like\n",
    "```python\n",
    "# Perform initial search\n",
    "r = requests.get(zenodo_search_url, params=search_params)\n",
    "output = r.json()\n",
    "\n",
    "if not r.status_code == 200 and output.get('hits').get('hits'):\n",
    "    return None\n",
    "\n",
    "cumulative_df = pd.DataFrame()\n",
    "\n",
    "while r.status_code == 200 and output['links'].get('next'):\n",
    "    # Get hits output\n",
    "    hits_df = pd.DataFrame(output['hits']['hits'])\n",
    "    \n",
    "    # Append results to df\n",
    "    cumulative_df = pd.concat([cumulative_df, hits_df]).reset_index(drop=True)\n",
    "    \n",
    "    # Get new results\n",
    "    r = requests.get(zenodo_search_url, params=search_params)\n",
    "    output = r.json()\n",
    "\n",
    "return cumulative_df\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc90cdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zenodo_search_output(search_term):\n",
    "    \"\"\"Return the output for a Zenodo record query.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    search_term : str\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    cumulative_df : pandas.DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    assert isinstance(search_term, str)\n",
    "    \n",
    "    search_url = 'https://zenodo.org/api/records'\n",
    "    print('first search')\n",
    "    search_params = {'q': search_term, 'size': 100} # Perform initial search\n",
    "    print('finished first search')\n",
    "    \n",
    "    r = requests.get(search_url, params=search_params)\n",
    "    output = r.json()\n",
    "\n",
    "    if not r.status_code == 200 and output.get('hits').get('hits'):\n",
    "        return None\n",
    "\n",
    "    cumulative_df = pd.DataFrame()\n",
    "\n",
    "    while r.status_code == 200 and output['links'].get('next'):\n",
    "        print('searching...')\n",
    "        # Get hits output\n",
    "        hits_df = pd.DataFrame(output['hits']['hits'])\n",
    "\n",
    "        # Append results to df\n",
    "        cumulative_df = pd.concat([cumulative_df, hits_df]).reset_index(drop=True)\n",
    "\n",
    "        # Get new results\n",
    "        r = requests.get(output['links'].get('next'))\n",
    "        output = r.json()\n",
    "    \n",
    "    hits_df = pd.DataFrame(output['hits']['hits'])\n",
    "    cumulative_df = pd.concat([cumulative_df, hits_df])\n",
    "\n",
    "    return cumulative_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ed2a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_zenodo_search_output('basketball')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02d74b8",
   "metadata": {},
   "source": [
    "Now we see that we're getting all of the results we wanted, so our job here is done. Let's take a look at some of the challenges that we could run into when using this API, which also often come up for other API's.\n",
    "\n",
    "- Cirmumventing 10,000 record maximum\n",
    "    Say we want to get all of the records for a term that has more than 10,000 results. The API is going to limit us, but surely there has to be some way around that. This is a somewhat common restriction with APIs, and it's caused me quite a bit of headache. I wanted to retrieve all 34,000 \"machine learning\" results from Figshare, which is another research repository, but they have a similar restriction. While you can't always beat the limit, let's do some brain-storming about how to see if it would be possible."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
